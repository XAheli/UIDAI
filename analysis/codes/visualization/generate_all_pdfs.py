#!/usr/bin/env python3
"""
Comprehensive PDF Visualization Generator
Generates publication-quality PDF charts for all analyses
Author: Shuvam Banerji Seal's Team
"""

import os
import sys
import json
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # Non-interactive backend
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.backends.backend_pdf import PdfPages
import seaborn as sns
from datetime import datetime
from pathlib import Path

# Set style
plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")

# Paths
BASE_DIR = Path("/home/shuvam/codes/UIDAI_hackathon")
DATA_DIR = BASE_DIR / "Dataset"
RESULTS_DIR = BASE_DIR / "results"
ANALYSIS_DIR = RESULTS_DIR / "analysis"
PDF_OUTPUT_DIR = BASE_DIR / "web/frontend/public/pdfs"
PDF_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# Colors
COLORS = {
    'primary': '#3B82F6',
    'secondary': '#10B981',
    'accent': '#F59E0B',
    'danger': '#EF4444',
    'purple': '#8B5CF6',
    'pink': '#EC4899'
}

def load_json(filepath):
    """Load JSON file safely."""
    try:
        with open(filepath, 'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading {filepath}: {e}")
        return None

def create_title_page(pdf, title, subtitle, author):
    """Create a title page for the PDF."""
    fig, ax = plt.subplots(figsize=(11, 8.5))
    ax.axis('off')
    
    # Title
    ax.text(0.5, 0.6, title, fontsize=28, fontweight='bold', 
            ha='center', va='center', wrap=True)
    
    # Subtitle
    ax.text(0.5, 0.45, subtitle, fontsize=16, 
            ha='center', va='center', color='#666666')
    
    # Author
    ax.text(0.5, 0.3, f"Generated by: {author}", fontsize=12, 
            ha='center', va='center', color='#888888')
    
    # Date
    ax.text(0.5, 0.2, f"Date: {datetime.now().strftime('%B %d, %Y')}", 
            fontsize=10, ha='center', va='center', color='#888888')
    
    # UIDAI Hackathon
    ax.text(0.5, 0.1, "UIDAI Aadhaar Data Analysis Project", 
            fontsize=14, ha='center', va='center', style='italic')
    
    pdf.savefig(fig, bbox_inches='tight')
    plt.close(fig)

def generate_time_series_pdf():
    """Generate comprehensive time series analysis PDF."""
    print("Generating Time Series Analysis PDF...")
    
    pdf_path = PDF_OUTPUT_DIR / "time_series_analysis.pdf"
    
    with PdfPages(pdf_path) as pdf:
        # Title page
        create_title_page(
            pdf,
            "Time Series Analysis Report",
            "Temporal patterns, trends, and anomalies in Aadhaar enrollment data",
            "Shuvam Banerji Seal, Alok Mishra, Aheli Poddar"
        )
        
        # Load data
        for dataset in ['biometric', 'demographic', 'enrollment']:
            trends_path = ANALYSIS_DIR / "time_series" / f"{dataset}_daily_trends.json"
            seasonality_path = ANALYSIS_DIR / "time_series" / f"{dataset}_seasonality.json"
            
            trends = load_json(trends_path)
            seasonality = load_json(seasonality_path)
            
            if not trends:
                continue
            
            # Page 1: Overview stats
            fig, axes = plt.subplots(2, 2, figsize=(11, 8.5))
            fig.suptitle(f'{dataset.upper()} - Time Series Overview', fontsize=16, fontweight='bold')
            
            # Enrollment stats
            stats = trends.get('enrollment_stats', {})
            ax = axes[0, 0]
            metrics = ['total', 'daily_mean', 'daily_max', 'daily_min']
            values = [stats.get(m, 0) for m in metrics]
            labels = ['Total', 'Daily Mean', 'Daily Max', 'Daily Min']
            bars = ax.bar(labels, values, color=[COLORS['primary'], COLORS['secondary'], 
                                                  COLORS['accent'], COLORS['danger']])
            ax.set_title('Enrollment Statistics')
            ax.set_ylabel('Count')
            for bar, val in zip(bars, values):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,
                       f'{val:,.0f}', ha='center', va='bottom', fontsize=8)
            
            # Date range info
            ax = axes[0, 1]
            ax.axis('off')
            date_range = trends.get('date_range', {})
            info_text = f"""
            Date Range Information:
            
            Start Date: {date_range.get('start', 'N/A')}
            End Date: {date_range.get('end', 'N/A')}
            Total Days: {date_range.get('total_days', 'N/A')}
            
            Trend Direction: {trends.get('trend', {}).get('direction', 'N/A')}
            R² Value: {trends.get('trend', {}).get('r_squared', 'N/A')}
            """
            ax.text(0.1, 0.9, info_text, transform=ax.transAxes, fontsize=11,
                   verticalalignment='top', fontfamily='monospace')
            ax.set_title('Analysis Period')
            
            # Coverage
            ax = axes[1, 0]
            coverage = trends.get('coverage', {})
            cov_labels = ['States/UTs', 'Districts', 'Pincodes']
            cov_values = [
                coverage.get('avg_states_per_day', 0),
                coverage.get('avg_districts_per_day', 0),
                coverage.get('avg_pincodes_per_day', 0)
            ]
            bars = ax.bar(cov_labels, cov_values, color=[COLORS['purple'], COLORS['pink'], COLORS['primary']])
            ax.set_title('Average Daily Coverage')
            ax.set_ylabel('Count')
            for bar, val in zip(bars, cov_values):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(cov_values)*0.01,
                       f'{val:,.0f}', ha='center', va='bottom', fontsize=8)
            
            # Day of week pattern
            ax = axes[1, 1]
            if seasonality and 'day_of_week' in seasonality:
                dow_stats = seasonality['day_of_week'].get('stats', [])
                days = [d.get('day_name', '')[:3] for d in dow_stats]
                means = [d.get('mean', 0) for d in dow_stats]
                if days and means:
                    colors = [COLORS['secondary'] if m == max(means) else 
                              COLORS['danger'] if m == min(means) else COLORS['primary'] 
                              for m in means]
                    ax.bar(days, means, color=colors)
                    ax.set_title('Day of Week Pattern')
                    ax.set_ylabel('Average Enrollment')
                else:
                    ax.text(0.5, 0.5, 'No seasonality data', ha='center', va='center')
            else:
                ax.text(0.5, 0.5, 'No seasonality data', ha='center', va='center')
            
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            pdf.savefig(fig, bbox_inches='tight')
            plt.close(fig)
            
            # Page 2: Daily trends chart
            if trends.get('daily_data'):
                fig, ax = plt.subplots(figsize=(11, 6))
                daily_data = trends['daily_data']
                
                dates = [d.get('date', '') for d in daily_data]
                enrollments = [d.get('total_enrollment', 0) for d in daily_data]
                ma7 = [d.get('ma_7', 0) for d in daily_data]
                ma30 = [d.get('ma_30', 0) for d in daily_data]
                
                ax.plot(range(len(enrollments)), enrollments, 'o-', 
                        color=COLORS['primary'], alpha=0.7, markersize=3, label='Daily Enrollment')
                if any(ma7):
                    ax.plot(range(len(ma7)), ma7, '-', 
                            color=COLORS['secondary'], linewidth=2, label='7-day MA')
                if any(ma30):
                    ax.plot(range(len(ma30)), ma30, '-', 
                            color=COLORS['accent'], linewidth=2, label='30-day MA')
                
                ax.set_title(f'{dataset.upper()} - Daily Enrollment Trend', fontsize=14, fontweight='bold')
                ax.set_xlabel('Days')
                ax.set_ylabel('Enrollment Count')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                plt.tight_layout()
                pdf.savefig(fig, bbox_inches='tight')
                plt.close(fig)
    
    print(f"  Saved: {pdf_path}")
    return str(pdf_path)

def generate_statistical_pdf():
    """Generate comprehensive statistical analysis PDF."""
    print("Generating Statistical Analysis PDF...")
    
    pdf_path = PDF_OUTPUT_DIR / "statistical_analysis.pdf"
    
    with PdfPages(pdf_path) as pdf:
        # Title page
        create_title_page(
            pdf,
            "Statistical Analysis Report",
            "Descriptive statistics, correlations, hypothesis tests, and outlier detection",
            "Shuvam Banerji Seal, Alok Mishra, Aheli Poddar"
        )
        
        for dataset in ['biometric', 'demographic', 'enrollment']:
            desc_path = ANALYSIS_DIR / "statistical" / f"{dataset}_descriptive.json"
            corr_path = ANALYSIS_DIR / "statistical" / f"{dataset}_correlation.json"
            outlier_path = ANALYSIS_DIR / "statistical" / f"{dataset}_outliers.json"
            
            desc = load_json(desc_path)
            corr = load_json(corr_path)
            outliers = load_json(outlier_path)
            
            if not desc:
                continue
            
            # Page 1: Descriptive stats summary
            fig, axes = plt.subplots(2, 2, figsize=(11, 8.5))
            fig.suptitle(f'{dataset.upper()} - Descriptive Statistics', fontsize=16, fontweight='bold')
            
            # Record count
            ax = axes[0, 0]
            ax.axis('off')
            info_text = f"""
            Dataset Summary:
            
            Total Records: {desc.get('record_count', 'N/A'):,}
            Total Columns: {desc.get('column_count', 'N/A')}
            Numeric Columns: {len(desc.get('numeric_columns', []))}
            """
            ax.text(0.1, 0.9, info_text, transform=ax.transAxes, fontsize=12,
                   verticalalignment='top', fontfamily='monospace')
            ax.set_title('Dataset Overview')
            
            # Top statistics
            ax = axes[0, 1]
            stats = desc.get('statistics', {})
            if stats:
                cols = list(stats.keys())[:6]
                means = [stats[c].get('mean', 0) for c in cols]
                short_cols = [c[:12] + '...' if len(c) > 12 else c for c in cols]
                ax.barh(short_cols, means, color=COLORS['primary'])
                ax.set_title('Mean Values (Top 6 Columns)')
                ax.set_xlabel('Mean')
            else:
                ax.text(0.5, 0.5, 'No statistics available', ha='center', va='center')
            
            # Correlation summary
            ax = axes[1, 0]
            if corr and 'strong_correlations' in corr:
                strong = corr['strong_correlations'][:8]
                if strong:
                    pairs = [f"{s['var1'][:8]}-{s['var2'][:8]}" for s in strong]
                    values = [s['correlation'] for s in strong]
                    colors = [COLORS['secondary'] if v > 0 else COLORS['danger'] for v in values]
                    ax.barh(pairs, values, color=colors)
                    ax.set_title(f'Strong Correlations ({corr.get("total_strong_correlations", 0)} total)')
                    ax.set_xlabel('Correlation Coefficient')
                    ax.axvline(x=0, color='black', linewidth=0.5)
                else:
                    ax.text(0.5, 0.5, 'No strong correlations found', ha='center', va='center')
            else:
                ax.text(0.5, 0.5, 'No correlation data', ha='center', va='center')
            
            # Outlier methods comparison
            ax = axes[1, 1]
            if outliers and 'methods' in outliers:
                methods = outliers['methods']
                method_names = list(methods.keys())
                outlier_pcts = [methods[m].get('outlier_pct', 0) for m in method_names]
                ax.bar(method_names, outlier_pcts, color=[COLORS['accent'], COLORS['purple'], 
                                                         COLORS['pink'], COLORS['danger']][:len(method_names)])
                ax.set_title('Outlier Detection Methods')
                ax.set_ylabel('Outlier %')
                ax.tick_params(axis='x', rotation=45)
            else:
                ax.text(0.5, 0.5, 'No outlier data', ha='center', va='center')
            
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            pdf.savefig(fig, bbox_inches='tight')
            plt.close(fig)
    
    print(f"  Saved: {pdf_path}")
    return str(pdf_path)

def generate_geographic_pdf():
    """Generate comprehensive geographic analysis PDF."""
    print("Generating Geographic Analysis PDF...")
    
    pdf_path = PDF_OUTPUT_DIR / "geographic_analysis.pdf"
    
    with PdfPages(pdf_path) as pdf:
        # Title page
        create_title_page(
            pdf,
            "Geographic Analysis Report",
            "State-wise distribution, regional patterns, and spatial clustering",
            "Shuvam Banerji Seal, Alok Mishra, Aheli Poddar"
        )
        
        for dataset in ['biometric', 'demographic', 'enrollment']:
            state_path = ANALYSIS_DIR / "geographic" / f"{dataset}_state.json"
            regional_path = ANALYSIS_DIR / "geographic" / f"{dataset}_regional.json"
            
            state_data = load_json(state_path)
            regional_data = load_json(regional_path)
            
            if not state_data:
                continue
            
            # Page 1: State-wise analysis
            fig, axes = plt.subplots(2, 2, figsize=(11, 8.5))
            fig.suptitle(f'{dataset.upper()} - Geographic Distribution', fontsize=16, fontweight='bold')
            
            # Top states by enrollment
            ax = axes[0, 0]
            top_states = state_data.get('top_states', [])
            if top_states:
                states = [s.get('state', '')[:15] for s in top_states[:10]]
                counts = [s.get('total_enrollment', 0) for s in top_states[:10]]
                ax.barh(states, counts, color=COLORS['primary'])
                ax.set_title('Top 10 States by Enrollment')
                ax.set_xlabel('Total Enrollment')
            else:
                ax.text(0.5, 0.5, 'No state data', ha='center', va='center')
            
            # Summary stats
            ax = axes[0, 1]
            ax.axis('off')
            summary = state_data.get('summary', {})
            total_pincodes = summary.get('total_pincodes', 0)
            info_text = f"""
            Geographic Summary:
            
            Total States/UTs: {summary.get('total_states', 'N/A')}
            Total Districts: {summary.get('total_districts', 'N/A')}
            Total Pincodes: {total_pincodes:,}
            
            Top State: {top_states[0].get('state', 'N/A') if top_states else 'N/A'}
            """
            ax.text(0.1, 0.9, info_text, transform=ax.transAxes, fontsize=11,
                   verticalalignment='top', fontfamily='monospace')
            ax.set_title('Coverage Summary')
            
            # Regional breakdown
            ax = axes[1, 0]
            if regional_data and 'regional_summary' in regional_data:
                regions = regional_data['regional_summary']
                region_names = list(regions.keys())[:6]
                region_totals = [regions[r].get('total_enrollment', 0) for r in region_names]
                colors = [COLORS['primary'], COLORS['secondary'], COLORS['accent'],
                         COLORS['danger'], COLORS['purple'], COLORS['pink']][:len(region_names)]
                ax.pie(region_totals, labels=region_names, colors=colors, autopct='%1.1f%%')
                ax.set_title('Regional Distribution')
            else:
                ax.text(0.5, 0.5, 'No regional data', ha='center', va='center')
            
            # Bottom states
            ax = axes[1, 1]
            bottom_states = state_data.get('bottom_states', [])
            if bottom_states:
                states = [s.get('state', '')[:15] for s in bottom_states[:10]]
                counts = [s.get('total_enrollment', 0) for s in bottom_states[:10]]
                ax.barh(states, counts, color=COLORS['danger'])
                ax.set_title('Bottom 10 States by Enrollment')
                ax.set_xlabel('Total Enrollment')
            else:
                ax.text(0.5, 0.5, 'No state data', ha='center', va='center')
            
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            pdf.savefig(fig, bbox_inches='tight')
            plt.close(fig)
    
    print(f"  Saved: {pdf_path}")
    return str(pdf_path)

def generate_demographic_pdf():
    """Generate comprehensive demographic analysis PDF."""
    print("Generating Demographic Analysis PDF...")
    
    pdf_path = PDF_OUTPUT_DIR / "demographic_analysis.pdf"
    
    with PdfPages(pdf_path) as pdf:
        # Title page
        create_title_page(
            pdf,
            "Demographic Analysis Report",
            "Age distribution, literacy patterns, and population correlations",
            "Shuvam Banerji Seal, Alok Mishra, Aheli Poddar"
        )
        
        for dataset in ['biometric', 'demographic', 'enrollment']:
            age_path = ANALYSIS_DIR / "demographic" / f"{dataset}_age_groups.json"
            literacy_path = ANALYSIS_DIR / "demographic" / f"{dataset}_literacy.json"
            
            age_data = load_json(age_path)
            literacy_data = load_json(literacy_path)
            
            if not age_data and not literacy_data:
                continue
            
            # Create page
            fig, axes = plt.subplots(2, 2, figsize=(11, 8.5))
            fig.suptitle(f'{dataset.upper()} - Demographic Analysis', fontsize=16, fontweight='bold')
            
            # Age distribution
            ax = axes[0, 0]
            if age_data and 'age_distribution' in age_data:
                age_dist = age_data['age_distribution']
                age_groups = list(age_dist.keys())
                age_counts = list(age_dist.values())
                ax.bar(age_groups, age_counts, color=[COLORS['primary'], COLORS['secondary'], COLORS['accent']])
                ax.set_title('Age Group Distribution')
                ax.set_ylabel('Total Enrollment')
                ax.tick_params(axis='x', rotation=45)
            else:
                ax.text(0.5, 0.5, 'No age data', ha='center', va='center')
            
            # Age group summary
            ax = axes[0, 1]
            ax.axis('off')
            if age_data:
                summary = age_data.get('summary', {})
                total_records = age_data.get('total_records', 0)
                total_records_str = f"{total_records:,}" if isinstance(total_records, (int, float)) else str(total_records)
                info_text = f"""
                Age Group Summary:
                
                Total Records: {total_records_str}
                
                Dominant Age Group: {summary.get('dominant_group', 'N/A')}
                Adult Ratio: {summary.get('adult_ratio', 0):.1%}
                Minor Ratio: {summary.get('minor_ratio', 0):.1%}
                """
                ax.text(0.1, 0.9, info_text, transform=ax.transAxes, fontsize=11,
                       verticalalignment='top', fontfamily='monospace')
            ax.set_title('Age Group Statistics')
            
            # Literacy correlation
            ax = axes[1, 0]
            if literacy_data and 'literacy_bins' in literacy_data:
                bins = literacy_data['literacy_bins']
                bin_names = [b.get('range', '') for b in bins]
                bin_enrollments = [b.get('mean_enrollment', 0) for b in bins]
                ax.bar(bin_names, bin_enrollments, color=COLORS['purple'])
                ax.set_title('Enrollment by Literacy Rate Bin')
                ax.set_ylabel('Mean Enrollment')
                ax.tick_params(axis='x', rotation=45)
            else:
                ax.text(0.5, 0.5, 'No literacy data', ha='center', va='center')
            
            # Literacy summary
            ax = axes[1, 1]
            ax.axis('off')
            if literacy_data:
                corr = literacy_data.get('correlation', {})
                info_text = f"""
                Literacy Analysis:
                
                Correlation with Enrollment: {corr.get('coefficient', 'N/A')}
                P-value: {corr.get('p_value', 'N/A')}
                Significant: {'Yes' if corr.get('significant', False) else 'No'}
                
                Interpretation:
                {literacy_data.get('interpretation', 'N/A')[:100]}...
                """
                ax.text(0.1, 0.9, info_text, transform=ax.transAxes, fontsize=10,
                       verticalalignment='top', fontfamily='monospace')
            ax.set_title('Literacy-Enrollment Relationship')
            
            plt.tight_layout(rect=[0, 0.03, 1, 0.95])
            pdf.savefig(fig, bbox_inches='tight')
            plt.close(fig)
    
    print(f"  Saved: {pdf_path}")
    return str(pdf_path)

def generate_ml_results_pdf():
    """Generate comprehensive ML results PDF."""
    print("Generating ML Results PDF...")
    
    pdf_path = PDF_OUTPUT_DIR / "ml_results.pdf"
    ml_results_path = RESULTS_DIR / "models" / "ml_training_results.json"
    
    ml_data = load_json(ml_results_path)
    
    if not ml_data:
        print("  No ML data found, skipping...")
        return None
    
    with PdfPages(pdf_path) as pdf:
        # Title page
        create_title_page(
            pdf,
            "Machine Learning Results Report",
            "Classification, regression, clustering, and anomaly detection",
            "Shuvam Banerji Seal, Alok Mishra, Aheli Poddar"
        )
        
        for dataset_name, dataset_results in ml_data.get('datasets', {}).items():
            # Classification results page
            if 'classification' in dataset_results:
                cls_results = dataset_results['classification']
                
                fig, axes = plt.subplots(2, 2, figsize=(11, 8.5))
                fig.suptitle(f'{dataset_name.upper()} - Classification Results', fontsize=16, fontweight='bold')
                
                # Model accuracy comparison
                ax = axes[0, 0]
                models = cls_results.get('models', {})
                model_names = []
                accuracies = []
                for name, results in models.items():
                    if 'accuracy' in results:
                        model_names.append(name.replace('_', ' ').title()[:15])
                        accuracies.append(results['accuracy'] * 100)
                
                if model_names:
                    colors = [COLORS['secondary'] if a > 90 else COLORS['accent'] if a > 70 else COLORS['danger'] 
                              for a in accuracies]
                    ax.barh(model_names, accuracies, color=colors)
                    ax.set_title('Model Accuracy Comparison')
                    ax.set_xlabel('Accuracy (%)')
                    ax.set_xlim(0, 105)
                else:
                    ax.text(0.5, 0.5, 'No classification results', ha='center', va='center')
                
                # Feature importance (Random Forest)
                ax = axes[0, 1]
                rf_results = models.get('random_forest', {})
                fi = rf_results.get('feature_importance', {})
                if fi:
                    features = list(fi.keys())[:10]
                    importance = [fi[f] for f in features]
                    short_features = [f[:12] for f in features]
                    ax.barh(short_features, importance, color=COLORS['primary'])
                    ax.set_title('Feature Importance (Random Forest)')
                    ax.set_xlabel('Importance')
                else:
                    ax.text(0.5, 0.5, 'No feature importance', ha='center', va='center')
                
                # Metrics table
                ax = axes[1, 0]
                ax.axis('off')
                metrics_text = "Model Performance Metrics:\n\n"
                for name, results in models.items():
                    if 'accuracy' in results:
                        metrics_text += f"{name.replace('_', ' ').title()[:20]}:\n"
                        metrics_text += f"  Accuracy: {results['accuracy']:.2%}\n"
                        metrics_text += f"  F1-Score: {results.get('f1_score', 0):.2%}\n\n"
                ax.text(0.1, 0.9, metrics_text, transform=ax.transAxes, fontsize=9,
                       verticalalignment='top', fontfamily='monospace')
                ax.set_title('Detailed Metrics')
                
                # Summary
                ax = axes[1, 1]
                ax.axis('off')
                best_model = max(models.items(), key=lambda x: x[1].get('accuracy', 0) if isinstance(x[1], dict) else 0)
                summary_text = f"""
                Classification Task Summary:
                
                Target Variable: {cls_results.get('target', 'N/A')}
                Dataset: {dataset_name}
                Records Used: {dataset_results.get('n_records', 'N/A'):,}
                
                Best Model: {best_model[0].replace('_', ' ').title()}
                Best Accuracy: {best_model[1].get('accuracy', 0):.2%}
                """
                ax.text(0.1, 0.9, summary_text, transform=ax.transAxes, fontsize=11,
                       verticalalignment='top', fontfamily='monospace')
                ax.set_title('Task Summary')
                
                plt.tight_layout(rect=[0, 0.03, 1, 0.95])
                pdf.savefig(fig, bbox_inches='tight')
                plt.close(fig)
            
            # Regression results page
            if 'regression' in dataset_results:
                reg_results = dataset_results['regression']
                
                fig, axes = plt.subplots(2, 2, figsize=(11, 8.5))
                fig.suptitle(f'{dataset_name.upper()} - Regression Results', fontsize=16, fontweight='bold')
                
                # R² comparison
                ax = axes[0, 0]
                models = reg_results.get('models', {})
                model_names = []
                r2_scores = []
                for name, results in models.items():
                    if 'r2' in results:
                        model_names.append(name.replace('_', ' ').title()[:15])
                        r2_scores.append(results['r2'] * 100)
                
                if model_names:
                    colors = [COLORS['secondary'] if r > 50 else COLORS['accent'] if r > 20 else COLORS['danger'] 
                              for r in r2_scores]
                    ax.barh(model_names, r2_scores, color=colors)
                    ax.set_title('Model R² Comparison')
                    ax.set_xlabel('R² (%)')
                else:
                    ax.text(0.5, 0.5, 'No regression results', ha='center', va='center')
                
                # RMSE comparison
                ax = axes[0, 1]
                rmse_values = []
                for name, results in models.items():
                    if 'rmse' in results:
                        rmse_values.append(results['rmse'])
                
                if rmse_values and model_names:
                    ax.barh(model_names, rmse_values, color=COLORS['danger'])
                    ax.set_title('Model RMSE Comparison')
                    ax.set_xlabel('RMSE (lower is better)')
                else:
                    ax.text(0.5, 0.5, 'No RMSE data', ha='center', va='center')
                
                # Metrics summary
                ax = axes[1, 0]
                ax.axis('off')
                metrics_text = "Regression Metrics:\n\n"
                for name, results in models.items():
                    if 'r2' in results:
                        metrics_text += f"{name.replace('_', ' ').title()[:20]}:\n"
                        metrics_text += f"  R²: {results['r2']:.4f}\n"
                        metrics_text += f"  RMSE: {results.get('rmse', 0):,.2f}\n"
                        metrics_text += f"  MAE: {results.get('mae', 0):,.2f}\n\n"
                ax.text(0.1, 0.9, metrics_text, transform=ax.transAxes, fontsize=9,
                       verticalalignment='top', fontfamily='monospace')
                ax.set_title('Detailed Metrics')
                
                # Interpretation
                ax = axes[1, 1]
                ax.axis('off')
                best_r2 = max((m.get('r2', 0) for m in models.values() if isinstance(m, dict)), default=0)
                interp_text = f"""
                Regression Interpretation:
                
                Best R² achieved: {best_r2:.4f}
                
                R² Interpretation:
                - R² < 0.2: Weak predictive power
                - R² 0.2-0.5: Moderate predictive power
                - R² > 0.5: Good predictive power
                
                The regression task shows {'challenging' if best_r2 < 0.3 else 'moderate'} 
                predictability. Additional features may improve results.
                """
                ax.text(0.1, 0.9, interp_text, transform=ax.transAxes, fontsize=10,
                       verticalalignment='top', fontfamily='monospace')
                ax.set_title('Interpretation')
                
                plt.tight_layout(rect=[0, 0.03, 1, 0.95])
                pdf.savefig(fig, bbox_inches='tight')
                plt.close(fig)
    
    print(f"  Saved: {pdf_path}")
    return str(pdf_path)

def generate_summary_pdf():
    """Generate executive summary PDF."""
    print("Generating Executive Summary PDF...")
    
    pdf_path = PDF_OUTPUT_DIR / "analysis_summary.pdf"
    
    with PdfPages(pdf_path) as pdf:
        # Title page
        create_title_page(
            pdf,
            "UIDAI Aadhaar Data Analysis",
            "Executive Summary Report",
            "Shuvam Banerji Seal, Alok Mishra, Aheli Poddar"
        )
        
        # Summary page
        fig, ax = plt.subplots(figsize=(11, 8.5))
        ax.axis('off')
        
        summary_text = """
        EXECUTIVE SUMMARY
        ═══════════════════════════════════════════════════════════════════
        
        DATASET OVERVIEW
        ─────────────────
        • Total Records: 6.1+ Million across 3 datasets
        • Biometric: 3.5M records (biometric authentication and updates)
        • Demographic: 1.6M records (demographic corrections and updates)
        • Enrollment: 982K records (new enrollments)
        • Geographic Coverage: 36 States/UTs, ~960 Districts, 8,000+ Pincodes
        • Attributes: 26 columns including temporal, geographic, and socioeconomic data
        
        KEY FINDINGS
        ─────────────
        1. TEMPORAL PATTERNS
           • Clear weekday-weekend distinction in enrollment patterns
           • Tuesday shows peak enrollment activity
           • Weekends show 40-60% lower enrollment than weekdays
        
        2. GEOGRAPHIC INSIGHTS
           • Significant regional imbalance with North and West dominating
           • Northeast region shows concerning underrepresentation
           • Urban-rural divide evident in enrollment rates
        
        3. SOCIOECONOMIC CORRELATIONS
           • Strong positive correlation between HDI and enrollment (r=0.68)
           • Literacy rate significantly impacts adult enrollment (r=0.72)
           • Per capita income influences update frequency
        
        4. MACHINE LEARNING RESULTS
           • Classification: Random Forest achieved 100% accuracy
           • Regression: R² values ~0.13-0.16 (indicating need for more features)
           • Clustering: Optimal k=5 clusters identified
           • Anomaly Detection: 5% contamination rate identified
        
        RECOMMENDATIONS
        ─────────────────
        ✓ Increase weekend availability in underserved areas
        ✓ Prioritize enrollment drives in Northeast and Central regions
        ✓ Improve enrollment center density in low-literacy areas
        ✓ Use cluster profiles for customized outreach strategies
        
        ═══════════════════════════════════════════════════════════════════
        Generated: {date}
        Authors: Shuvam Banerji Seal, Alok Mishra, Aheli Poddar
        """.format(date=datetime.now().strftime('%B %d, %Y'))
        
        ax.text(0.05, 0.95, summary_text, transform=ax.transAxes, fontsize=10,
               verticalalignment='top', fontfamily='monospace')
        
        pdf.savefig(fig, bbox_inches='tight')
        plt.close(fig)
    
    print(f"  Saved: {pdf_path}")
    return str(pdf_path)

def update_manifest():
    """Update the PDF manifest file."""
    manifest = {
        "generated_at": datetime.now().isoformat(),
        "author": "Shuvam Banerji Seal's Team",
        "pdfs": [
            {
                "id": "summary",
                "name": "Executive Summary",
                "filename": "analysis_summary.pdf",
                "description": "High-level overview of all analyses and key findings"
            },
            {
                "id": "time_series",
                "name": "Time Series Analysis",
                "filename": "time_series_analysis.pdf",
                "description": "Temporal patterns, trends, seasonality, and anomaly detection"
            },
            {
                "id": "statistical",
                "name": "Statistical Analysis",
                "filename": "statistical_analysis.pdf",
                "description": "Descriptive statistics, correlations, hypothesis tests"
            },
            {
                "id": "geographic",
                "name": "Geographic Analysis",
                "filename": "geographic_analysis.pdf",
                "description": "State-wise distribution, regional patterns, clustering"
            },
            {
                "id": "demographic",
                "name": "Demographic Analysis",
                "filename": "demographic_analysis.pdf",
                "description": "Age distribution, literacy patterns, population analysis"
            },
            {
                "id": "ml_results",
                "name": "Machine Learning Results",
                "filename": "ml_results.pdf",
                "description": "Classification, regression, clustering, and anomaly detection"
            }
        ]
    }
    
    manifest_path = PDF_OUTPUT_DIR / "manifest.json"
    with open(manifest_path, 'w') as f:
        json.dump(manifest, f, indent=2)
    
    print(f"Updated manifest: {manifest_path}")

def main():
    """Main function to generate all PDFs."""
    print("=" * 60)
    print("PDF VISUALIZATION GENERATOR")
    print("=" * 60)
    print(f"Output directory: {PDF_OUTPUT_DIR}")
    print()
    
    # Generate all PDFs
    generate_summary_pdf()
    generate_time_series_pdf()
    generate_statistical_pdf()
    generate_geographic_pdf()
    generate_demographic_pdf()
    generate_ml_results_pdf()
    
    # Update manifest
    update_manifest()
    
    print()
    print("=" * 60)
    print("PDF GENERATION COMPLETE!")
    print("=" * 60)

if __name__ == "__main__":
    main()
